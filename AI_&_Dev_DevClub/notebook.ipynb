{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0304b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   id                300000 non-null  int64 \n",
      " 1   date              300000 non-null  object\n",
      " 2   likes             300000 non-null  int64 \n",
      " 3   content           300000 non-null  object\n",
      " 4   username          300000 non-null  object\n",
      " 5   media             300000 non-null  object\n",
      " 6   inferred company  300000 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 16.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "date                0\n",
       "likes               0\n",
       "content             0\n",
       "username            0\n",
       "media               0\n",
       "inferred company    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"behaviour_simulation_train.csv\")\n",
    "\n",
    "# print(df.shape)\n",
    "df.shape #(300000, 7)\n",
    "df.head()\n",
    "\n",
    "# print(df.head())\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c19b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light Preprocessing\n",
    "df.dropna(subset=['content', 'username', 'inferred company', 'likes'], inplace=True) #1. Remove rows with missing critical data\n",
    "\n",
    "#inplace=True means it modifies the original DataFrame directly (no need to assign back to df)\n",
    "\n",
    "df.fillna({'media':'no_media'}, inplace=True) #2. Fill missing media field with a placeholder\n",
    "\n",
    "#Replaces all NaN values in the media column with the string 'no_media'.\n",
    "# Makes the column consistent and easier to work with (no more null checks).\n",
    "# Helps in creating features like has_media for modeling or filtering.\n",
    "\n",
    "\n",
    "df['has_media'] = df['media'].apply(lambda x: x != 'no_media').astype(int)\n",
    "#Adds a new boolean column (True or False) indicating whether a row includes media.\n",
    "\n",
    "df['content'] = df['content'].astype(str).str.strip().str.lower()\n",
    "\n",
    "#.astype(str): Converts all values to string type (\" \") (handles any non-text data)\n",
    "# Similar posts with different cases are identified\n",
    "# Case-insensitive searching\n",
    "\n",
    "\n",
    "df['datetime'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "# Converts the 'date' column to proper datetime format\n",
    "# errors='coerce': Invalid dates become NaT (Not a Time) instead of raising errors\n",
    "#strings become proper datetime obejcts , easy to analyze, filter, order and extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# df['likes'] = df['likes'].fillna(0)\n",
    "\n",
    "sns.histplot(df['likes'], kde=True,  log_scale=True)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=df['likes'])\n",
    "plt.xlim(0,100000)\n",
    "plt.show()\n",
    "\n",
    "#very few posts with high likes\n",
    "#can be broadly categorised as normal posts and branded posts\n",
    "#normal posts mainly in region before 10^3 likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7492ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['datetime'].dt.year\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek # 0=Monday, 6=Sunday\n",
    "\n",
    "df['word_count'] = df['content'].apply(lambda x: len(x.split()))\n",
    "df['char_count'] = df['content'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f074e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature to identify branded vs non-branded posts\n",
    "\n",
    "# Text features\n",
    "promotional_words = ['buy', 'sale', 'discount', 'offer', 'deal', 'shop']\n",
    "df['promo_word_count'] = df['content'].str.count('|'.join(promotional_words))\n",
    "df['has_url'] = df['content'].str.contains(r'http|www|\\.com', case=False).astype(int) # Added r prefix for raw string\n",
    "df['hashtag_count'] = df['content'].str.count('#')\n",
    "df['mention_count'] = df['content'].str.count('@')\n",
    "\n",
    "# Engagement features\n",
    "# df['engagement_rate'] = (df['likes'] + df['comments']) / df['followers']\n",
    "# df['like_comment_ratio'] = df['likes'] / (df['comments'] + 1)\n",
    "\n",
    "# Would have been useful had we known no of comments or followers of user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d580aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying sentiments\n",
    "\n",
    "# analyze the sentiment polarity and subjectivity of a given text.\n",
    "\n",
    "# Polarity: A float within the range [-1.0, 1.0]\n",
    "\n",
    "# -1.0: Very negative sentiment\n",
    "# 0.0: Neutral\n",
    "# 1.0: Very positive sentiment\n",
    "\n",
    "# Subjectivity: A float within the range [0.0, 1.0]\n",
    "\n",
    "# 0.0: Very objective (fact-based)\n",
    "# 1.0: Very subjective (opinion-based)\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "# TextBlob sentiment\n",
    "def compute_sentiment(text):\n",
    "    blob = TextBlob(str(text))\n",
    "    return pd.Series([blob.sentiment.polarity, blob.sentiment.subjectivity])\n",
    "\n",
    "# Apply the function to the 'content' column\n",
    "df[['polarity', 'subjectivity']] = df['content'].apply(compute_sentiment)\n",
    "\n",
    "def label_sentiment(p):\n",
    "    if p > 0.1:\n",
    "        # return 'positive'\n",
    "        return 1\n",
    "    elif p < -0.1:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['sentiment_label'] = df['polarity'].apply(label_sentiment)\n",
    "    \n",
    "df['is_biased'] = df['subjectivity'].apply(lambda x: x > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324dc426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#  Named Entity Recognition (NER) to identify brands, places,\n",
    "#  extract only brands (ORG) or places (GPE):\n",
    "def extract_filtered_entities(text, types={'ORG', 'GPE'}):\n",
    "    doc = nlp(str(text))\n",
    "    return [ent.text for ent in doc.ents if ent.label_ in types]\n",
    "\n",
    "df['filtered_entities'] = df['content'].apply(lambda x: extract_filtered_entities(x))\n",
    "\n",
    "# Preview result\n",
    "# print(df['filtered_entities'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WEEK 2\n",
    "\n",
    "#Converting features to numeric before training\n",
    "\n",
    "\n",
    "df['entity_count'] = df['filtered_entities'].apply(len)\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from collections import Counter\n",
    "\n",
    "# Get top 50 most common entities\n",
    "all_entities = [e for lst in df['filtered_entities'] for e in lst]\n",
    "\n",
    "top_entities = dict(Counter(all_entities).most_common(50))\n",
    "\n",
    "# Create binary features\n",
    "# Creates a tool that converts lists of labels into binary (0/1) arrays\n",
    "# classes=list(top_entities.keys()) tells exactly which entities to look for (your top 50)\n",
    "# This ensures consistent columns even if some entities don't appear in every row\n",
    "mlb = MultiLabelBinarizer(classes=list(top_entities.keys()))\n",
    "\n",
    "# Takes filtered_entities column (lists of entities like ['Apple', 'Google'])\n",
    "# Converts each list into a binary array\n",
    "entity_features = mlb.fit_transform(df['filtered_entities'])\n",
    "\n",
    "# Add as new columns to existing df\n",
    "for i, entity in enumerate(mlb.classes_):\n",
    "   df[f'entity_{entity}'] = entity_features[:, i]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['company_encoded'] = le.fit_transform(df['inferred company'])\n",
    "df['username_encoded'] = le.fit_transform(df['username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f0db87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
